{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2s0EJ5Fy4u2"
   },
   "source": [
    "# Week 2: Implementing Callbacks in TensorFlow using the MNIST Dataset\n",
    "\n",
    "In the lectures you learned how to do classification using Fashion MNIST, a dataset containing items of clothing. There's another, similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
    "\n",
    "In this assignment you will code a classifier for the MNIST dataset, that trains until it reaches 98% accuracy and stops once this threshold is achieved. In the lectures you saw how this was done for the loss but here you will be using accuracy instead.\n",
    "\n",
    "Some notes:\n",
    "1. Your network should succeed in less than 10 epochs.\n",
    "2. When it reaches 98% or greater it should print out the string \"Reached 98% accuracy so cancelling training!\" and stop training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TIPS FOR SUCCESSFUL GRADING OF YOUR ASSIGNMENT:\n",
    "\n",
    "- All cells are frozen except for the ones where you need to submit your solutions or when explicitly mentioned you can interact with it.\n",
    "\n",
    "- You can add new cells to experiment but these will be omitted by the grader, so don't rely on newly created cells to host your solution code, use the provided places for this.\n",
    "\n",
    "- You can add the comment # grade-up-to-here in any graded cell to signal the grader that it must only evaluate up to that point. This is helpful if you want to check if you are on the right track even if you are not done with the whole assignment. Be sure to remember to delete the comment afterwards!\n",
    "\n",
    "- Avoid using global variables unless you absolutely have to. The grader tests your code in an isolated environment without running all cells from the top. As a result, global variables may be unavailable when scoring your submission. Global variables that are meant to be used will be defined in UPPERCASE.\n",
    "\n",
    "- To submit your notebook, save it and then click on the blue submit button at the beginning of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "djVOgMHty4u3",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'unittests'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8007/2191673041.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0munittests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'unittests'"
     ]
    }
   ],
   "source": [
    "import unittests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect the data\n",
    "\n",
    "Begin by loading the data. A couple of things to notice:\n",
    "\n",
    "- The file `mnist.npz` is already included in the current workspace under the `data` directory. By default the `load_data` from Keras accepts a path relative to `~/.keras/datasets` but in this case it is stored somewhere else, as a result of this, you need to specify the full path.\n",
    "\n",
    "- `tf.keras.datasets.mnist.load_data` returns the train and test sets in the form of the tuples `(training_images, training_labels), (testing_images, testing_labels)` but in this exercise you will be needing only the train set so you can ignore the second tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_images is of type <class 'numpy.ndarray'>.\n",
      "training_labels is of type <class 'numpy.ndarray'>\n",
      "\n",
      "There are 60000 examples with shape (28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Get current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Append data/mnist.npz to the previous path to get the full path\n",
    "data_path = os.path.join(current_dir, \"mnist.npz\")\n",
    "\n",
    "# Load data (discard test set)\n",
    "(training_images, training_labels), _ = tf.keras.datasets.mnist.load_data(path=data_path)\n",
    "\n",
    "print(f\"training_images is of type {type(training_images)}.\\ntraining_labels is of type {type(training_labels)}\\n\")\n",
    "\n",
    "# Inspect shape of the data\n",
    "data_shape = training_images.shape\n",
    "\n",
    "print(f\"There are {data_shape[0]} examples with shape ({data_shape[1]}, {data_shape[2]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label: 6')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx=2300\n",
    "plt.contourf(training_images[idx, ::-1,:])\n",
    "plt.title(f\"Label: {training_labels[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important step is to normalize the pixel values. The dataset includes black and white images and the pixel values for these kinds of images usually range from 0 to 255 but the network will have an easier time learning if these values range from 0 to 1.\n",
    "\n",
    "The data comes as numpy arrays so you can easily normalize the pixel values by using vectorization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Normalize pixel values\n",
    "training_images = training_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: create_and_compile_model\n",
    "\n",
    "Your first task is to create and compile the model that you will later train to recognize handwritten digits.\n",
    "\n",
    "Feel free to try the architecture for the neural network that you see fit but in case you need extra help you can check out an architecture that works pretty well at the end of this notebook. Notice that the part where the model is compiled is already provided (and the `accuracy` metric is defined so it can be accessed by your callback later on) so you only need to specify the layers of the model.\n",
    "\n",
    "Hints:\n",
    "- The first layer should take into consideration the `input_shape` of the data, which in this case is the size of each image\n",
    "- The last layer should take into account the number of classes you are trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: create_and_compile_model\n",
    "\n",
    "def create_and_compile_model():\n",
    "    \"\"\"Returns the compiled (but untrained) model.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The model that will be trained to predict predict handwriting digits.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.Input(shape=(28, 28)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell allows you to check the number of total and trainable parameters of your model and prompts a warning in case these exceeds those of a reference solution, this serves the following 3 purposes listed in order of priority:\n",
    "\n",
    "- Helps you prevent crashing the kernel during training.\n",
    "\n",
    "- Helps you avoid longer-than-necessary training times.\n",
    "- Provides a reasonable estimate of the size of your model. In general you will usually prefer smaller models given that they accomplish their goal successfully.\n",
    "\n",
    "**Notice that this is just informative** and may be very well below the actual limit for size of the model necessary to crash the kernel. So even if you exceed this reference you are probably fine. However, **if the kernel crashes during training or it is taking a very long time and your model is larger than the reference, come back here and try to get the number of parameters closer to the reference.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save untrained model in a variable\n",
    "untrained_model = create_and_compile_model()\n",
    "\n",
    "# Check parameter count against a reference solution\n",
    "# unittests.parameter_count(untrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions have shape: (5, 10)\n"
     ]
    }
   ],
   "source": [
    "# Use it to predict the first 5 images in the train set\n",
    "predictions = untrained_model.predict(training_images[:5], verbose=False)\n",
    "\n",
    "print(f\"predictions have shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "predictions have shape: (5, 10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.test_create_and_compile_model(create_and_compile_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: EarlyStoppingCallback\n",
    "\n",
    "Now it is time to create your own custom callback. For this complete the `EarlyStoppingCallback` class and the `on_epoch_end` method in the cell below. If you need some guidance on how to proceed, check out this [link](https://www.tensorflow.org/guide/keras/writing_your_own_callbacks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED CLASS: EarlyStoppingCallback\n",
    "\n",
    "### START CODE HERE ###\n",
    "\n",
    "# Remember to inherit from the correct class\n",
    "class EarlyStoppingCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, accuracy=0.98):\n",
    "        super(EarlyStoppingCallback, self).__init__()\n",
    "        self.accuracy = accuracy\n",
    "\n",
    "    # Define the correct function signature for on_epoch_end method\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Check if the accuracy is greater or equal to the specified accuracy\n",
    "        if logs.get('accuracy') >= self.accuracy:\n",
    "            # Stop training once the above condition is met\n",
    "            self.model.stop_training = True\n",
    "\n",
    "            print(f\"\\nReached {self.accuracy*100}% accuracy so cancelling training!\")\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "# unittests.test_EarlyStoppingCallback(EarlyStoppingCallback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: train_mnist\n",
    "\n",
    "Now that you have defined your callback it is time to complete the `train_mnist` function below. This function will receive the training data (features and targets encoded as numpy arrays) and should use it to train the model you defined earlier. It should also return the training history of the model. This object is returned when using the `fit` method of a `tf.keras.Model` as explained in the [docs](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit).\n",
    "\n",
    "**You must set your model to train for 10 epochs and the callback should fire before the 10th epoch for you to pass this part of the assignment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "id": "rEHcB3kqyHZ6",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_mnist\n",
    "\n",
    "def train_mnist(training_images, training_labels):\n",
    "    \"\"\"Trains a classifier of handwritten digits.\n",
    "\n",
    "    Args:\n",
    "        training_images (numpy.ndarray): The images of handwritten digits\n",
    "        training_labels (numpy.ndarray): The labels of each image\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.callbacks.History : The training history.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Create a compiled (but untrained) version of the model\n",
    "    # Hint: Remember you already coded a function that does this!\n",
    "    model = create_and_compile_model()\n",
    "\n",
    "    \n",
    "    # Fit the model for 10 epochs adding the callbacks and save the training history\n",
    "    history = model.fit(training_images, training_labels, epochs=10,\n",
    "                        callbacks=[EarlyStoppingCallback()])\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the model and get the training history by calling the `train_mnist` function, passing in the appropiate parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "sFgpwbGly4u4",
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.3327\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9736 - loss: 0.0821\n",
      "Epoch 3/10\n",
      "\u001b[1m1855/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0512\n",
      "Reached 98% accuracy so cancelling training!\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0512\n"
     ]
    }
   ],
   "source": [
    "training_history = train_mnist(training_images, training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "\n",
    "`Reached 98% accuracy so cancelling training!` printed out before reaching 10 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.test_training_history(training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need more help?\n",
    "\n",
    "Run the following cell to see an architecture that works well for the problem at hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   - A tf.keras.Input with the same shape as the images\n",
      "   - A Flatten layer\n",
      "   - A Dense layer with 512 units and ReLU activation function\n",
      "   - A Dense layer with 10 units and softmax activation function\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# WE STRONGLY RECOMMEND YOU TO TRY YOUR OWN ARCHITECTURES FIRST\n",
    "# AND ONLY RUN THIS CELL IF YOU WISH TO SEE AN ANSWER\n",
    "\n",
    "encoded_answer = \"CiAgIC0gQSB0Zi5rZXJhcy5JbnB1dCB3aXRoIHRoZSBzYW1lIHNoYXBlIGFzIHRoZSBpbWFnZXMKICAgLSBBIEZsYXR0ZW4gbGF5ZXIKICAgLSBBIERlbnNlIGxheWVyIHdpdGggNTEyIHVuaXRzIGFuZCBSZUxVIGFjdGl2YXRpb24gZnVuY3Rpb24KICAgLSBBIERlbnNlIGxheWVyIHdpdGggMTAgdW5pdHMgYW5kIHNvZnRtYXggYWN0aXZhdGlvbiBmdW5jdGlvbgo==\"\n",
    "encoded_answer = encoded_answer.encode('ascii')\n",
    "answer = base64.b64decode(encoded_answer)\n",
    "answer = answer.decode('ascii')\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations on finishing this week's assignment!**\n",
    "\n",
    "You have successfully implemented a callback that gives you more control over the training loop for your model. Nice job!\n",
    "\n",
    "**Keep it up!**"
   ]
  }
 ],
 "metadata": {
  "grader_version": "1",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
